{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSplitter_Holdout: Verifying data consistency...\n",
      "DataSplitter_Holdout: Verifying data consistency... Passed!\n",
      "DataSplitter_Holdout: DataReader: CiteULike_a\n",
      "\tNum items: 16980\n",
      "\tNum users: 5551\n",
      "\tTrain \t\tquota 80.00 (80.00), \tinteractions 163989, \tdensity 1.74E-03\n",
      "\tValidation \tquota 10.00 (10.00), \tinteractions 20498, \tdensity 2.17E-04\n",
      "\tTest \t\tquota 10.00 (10.00), \tinteractions 20499, \tdensity 2.17E-04\n",
      "\n",
      "\n",
      "\n",
      "\tICM name: ICM_title_abstract, Num features: 8000, feature occurrences: 1130920, density 8.33E-03\n",
      "\n",
      "\n",
      "DataSplitter_Holdout: Done.\n",
      "EvaluatorHoldout: Ignoring 740 (13.3%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 740 (13.3%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Data_manager.DataSplitter_Holdout import DataSplitter_Holdout\n",
    "from Data_manager.CiteULike.CiteULikeReader import CiteULike_aReader\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "import numpy as np\n",
    "\n",
    "dataset_reader = CiteULike_aReader()\n",
    "\n",
    "dataSplitter = DataSplitter_Holdout(dataset_reader, user_wise=False, split_interaction_quota_list=[80, 10, 10])\n",
    "dataSplitter.load_data(\"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/data\") #\"results_experiments/Movielens1M/data\"\n",
    "URM_train, URM_validation, URM_test = dataSplitter.get_holdout_split()\n",
    "\n",
    "cutoff_list = [10, 50]\n",
    "evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=cutoff_list)\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=cutoff_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender\n",
    "from Recommenders.MatrixFactorization.PureSVDRecommender import PureSVDRecommender\n",
    "from Recommenders.MatrixFactorization.IALSRecommender import IALSRecommender\n",
    "from Diffusion.DiffusionRecommender import DiffusionAutoencoderRecommender_OptimizerMask\n",
    "\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RecommenderLuca import TwoLevelRec\n",
    "import importlib\n",
    "\n",
    "# Make some changes to your_module.py\n",
    "\n",
    "importlib.reload(TwoLevelRec)\n",
    "from RecommenderLuca.TwoLevelRec import TwoLevelRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNCFRecommender: URM Detected 44 ( 0.3%) items with no interactions.\n",
      "ItemKNNCFRecommender: Loading model from file '/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models/ItemKNNCFRecommender_cosine_best_model'\n",
      "ItemKNNCFRecommender: Loading complete\n",
      "SLIMElasticNetRecommender: URM Detected 44 ( 0.3%) items with no interactions.\n",
      "SLIMElasticNetRecommender: Loading model from file '/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models/SLIMElasticNetRecommender_best_model'\n",
      "SLIMElasticNetRecommender: Loading complete\n",
      "IALSRecommender: URM Detected 44 ( 0.3%) items with no interactions.\n",
      "IALSRecommender: Loading model from file '/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models/IALSRecommender_best_model'\n",
      "IALSRecommender: Loading complete\n",
      "DiffusionAutoencoderRecommender: URM Detected 44 ( 0.3%) items with no interactions.\n",
      "DiffusionAutoencoderRecommender: Loading model from file '/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models/DiffusionAutoencoderRecommender_best_model'\n",
      "DiffusionAutoencoderRecommender: Loading complete\n"
     ]
    }
   ],
   "source": [
    "#load validation(best_model) models instances\n",
    "\n",
    "itemKNN_instance = ItemKNNCFRecommender(URM_train=URM_train)\n",
    "itemKNN_instance.load_model(folder_path=\"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models\", file_name=\"/ItemKNNCFRecommender_cosine_best_model\")\n",
    "\n",
    "slim_elastic_instance = SLIMElasticNetRecommender(URM_train=URM_train)\n",
    "slim_elastic_instance.load_model(folder_path=\"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models\", file_name=\"/SLIMElasticNetRecommender_best_model\")\n",
    "\n",
    "#matrix_fact_instance = PureSVDRecommender(URM_train=URM_train)\n",
    "#matrix_fact_instance.load_model(folder_path=\"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models\", file_name=\"/PureSVDRecommender_best_model\")\n",
    "\n",
    "matrix_fact_instance = IALSRecommender(URM_train=URM_train)\n",
    "matrix_fact_instance.load_model(folder_path=\"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models\", file_name=\"/IALSRecommender_best_model\")\n",
    "\n",
    "\n",
    "auto_diffusion_instance = DiffusionAutoencoderRecommender_OptimizerMask(URM_train=URM_train, use_gpu=False)\n",
    "auto_diffusion_instance.load_model(folder_path=\"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models\", file_name=\"/DiffusionAutoencoderRecommender_best_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNCFRecommender: URM Detected 19 ( 0.1%) items with no interactions.\n",
      "ItemKNNCFRecommender: Loading model from file '/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models/ItemKNNCFRecommender_cosine_best_model_last'\n",
      "ItemKNNCFRecommender: Loading complete\n",
      "SLIMElasticNetRecommender: URM Detected 44 ( 0.3%) items with no interactions.\n",
      "SLIMElasticNetRecommender: Loading model from file '/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models/SLIMElasticNetRecommender_best_model_last'\n",
      "SLIMElasticNetRecommender: Loading complete\n",
      "IALSRecommender: URM Detected 44 ( 0.3%) items with no interactions.\n",
      "IALSRecommender: Loading model from file '/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models/IALSRecommender_best_model_last'\n",
      "IALSRecommender: Loading complete\n",
      "DiffusionAutoencoderRecommender: URM Detected 44 ( 0.3%) items with no interactions.\n",
      "DiffusionAutoencoderRecommender: Loading model from file '/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models/DiffusionAutoencoderRecommender_best_model_last'\n",
      "DiffusionAutoencoderRecommender: Loading complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "itemKNN_instance_test = ItemKNNCFRecommender(URM_train=URM_train+URM_validation)\n",
    "itemKNN_instance_test.load_model(folder_path=\"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models\", file_name=\"/ItemKNNCFRecommender_cosine_best_model_last\")\n",
    "\n",
    "slim_elastic_instance_test = SLIMElasticNetRecommender(URM_train=URM_train)\n",
    "slim_elastic_instance_test.load_model(folder_path=\"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models\", file_name=\"/SLIMElasticNetRecommender_best_model_last\")\n",
    "\n",
    "#pure_svd_instance_test = PureSVDRecommender(URM_train=URM_train)\n",
    "#pure_svd_instance_test.load_model(folder_path=\"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models\", file_name=\"/PureSVDRecommender_best_model_last\")\n",
    "\n",
    "\n",
    "matrix_fact_instance_test = IALSRecommender(URM_train=URM_train)\n",
    "matrix_fact_instance_test.load_model(folder_path=\"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models\", file_name=\"/IALSRecommender_best_model_last\")\n",
    "\n",
    "\n",
    "auto_diffusion_instance_test = DiffusionAutoencoderRecommender_OptimizerMask(URM_train=URM_train, use_gpu=False)\n",
    "auto_diffusion_instance_test.load_model(folder_path=\"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/teams/CiteULike_a/models\", file_name=\"/DiffusionAutoencoderRecommender_best_model_last\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01755132 -0.02213416 -0.01201135 ...  0.00224747  0.00890158\n",
      "  -0.0176401 ]]\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 18.82 sec. Users per second: 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>PRECISION_RECALL_MIN_DEN</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MAP_MIN_DEN</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>F1</th>\n",
       "      <th>HIT_RATE</th>\n",
       "      <th>ARHR_ALL_HITS</th>\n",
       "      <th>...</th>\n",
       "      <th>COVERAGE_USER</th>\n",
       "      <th>COVERAGE_USER_HIT</th>\n",
       "      <th>USERS_IN_GT</th>\n",
       "      <th>DIVERSITY_GINI</th>\n",
       "      <th>SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_DIVERSITY_HERFINDAHL</th>\n",
       "      <th>RATIO_DIVERSITY_GINI</th>\n",
       "      <th>RATIO_SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_AVERAGE_POPULARITY</th>\n",
       "      <th>RATIO_NOVELTY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cutoff</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.039867</td>\n",
       "      <td>0.116394</td>\n",
       "      <td>0.115212</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>0.046442</td>\n",
       "      <td>0.087684</td>\n",
       "      <td>0.077995</td>\n",
       "      <td>0.059236</td>\n",
       "      <td>0.244024</td>\n",
       "      <td>0.11269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866691</td>\n",
       "      <td>0.211493</td>\n",
       "      <td>0.866691</td>\n",
       "      <td>0.392408</td>\n",
       "      <td>12.920359</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.632217</td>\n",
       "      <td>0.947302</td>\n",
       "      <td>1.217426</td>\n",
       "      <td>0.333459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.022665</td>\n",
       "      <td>0.233189</td>\n",
       "      <td>0.233189</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.062561</td>\n",
       "      <td>0.097302</td>\n",
       "      <td>0.122658</td>\n",
       "      <td>0.041314</td>\n",
       "      <td>0.43068</td>\n",
       "      <td>0.148738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866691</td>\n",
       "      <td>0.373266</td>\n",
       "      <td>0.866691</td>\n",
       "      <td>0.605587</td>\n",
       "      <td>13.602907</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>0.975675</td>\n",
       "      <td>0.997346</td>\n",
       "      <td>0.934779</td>\n",
       "      <td>1.706706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRECISION PRECISION_RECALL_MIN_DEN    RECALL       MAP MAP_MIN_DEN  \\\n",
       "cutoff                                                                      \n",
       "10      0.039867                 0.116394  0.115212  0.015361    0.046442   \n",
       "50      0.022665                 0.233189  0.233189  0.006179    0.062561   \n",
       "\n",
       "             MRR      NDCG        F1  HIT_RATE ARHR_ALL_HITS  ...  \\\n",
       "cutoff                                                        ...   \n",
       "10      0.087684  0.077995  0.059236  0.244024       0.11269  ...   \n",
       "50      0.097302  0.122658  0.041314   0.43068      0.148738  ...   \n",
       "\n",
       "       COVERAGE_USER COVERAGE_USER_HIT USERS_IN_GT DIVERSITY_GINI  \\\n",
       "cutoff                                                              \n",
       "10          0.866691          0.211493    0.866691       0.392408   \n",
       "50          0.866691          0.373266    0.866691       0.605587   \n",
       "\n",
       "       SHANNON_ENTROPY RATIO_DIVERSITY_HERFINDAHL RATIO_DIVERSITY_GINI  \\\n",
       "cutoff                                                                   \n",
       "10           12.920359                   0.999847             0.632217   \n",
       "50           13.602907                    0.99999             0.975675   \n",
       "\n",
       "       RATIO_SHANNON_ENTROPY RATIO_AVERAGE_POPULARITY RATIO_NOVELTY  \n",
       "cutoff                                                               \n",
       "10                  0.947302                 1.217426      0.333459  \n",
       "50                  0.997346                 0.934779      1.706706  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_diffusion_instance_test._set_inference_timesteps(1)\n",
    "print(auto_diffusion_instance_test._compute_item_score(10))\n",
    "result_df, _ =evaluator_test.evaluateRecommender(auto_diffusion_instance_test)\n",
    "result_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommender_Base_Class: URM Detected 19 ( 0.1%) items with no interactions.\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 5.98 sec. Users per second: 804\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 5.47 sec. Users per second: 880\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 6.03 sec. Users per second: 798\n",
      "Recommender_Base_Class: URM Detected 19 ( 0.1%) items with no interactions.\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 5.85 sec. Users per second: 823\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 5.51 sec. Users per second: 872\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 5.89 sec. Users per second: 817\n",
      "Recommender_Base_Class: URM Detected 19 ( 0.1%) items with no interactions.\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 5.86 sec. Users per second: 821\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 5.44 sec. Users per second: 884\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 5.73 sec. Users per second: 839\n",
      "Recommender_Base_Class: URM Detected 19 ( 0.1%) items with no interactions.\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 5.88 sec. Users per second: 818\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 5.52 sec. Users per second: 871\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 5.81 sec. Users per second: 828\n",
      "Recommender_Base_Class: URM Detected 19 ( 0.1%) items with no interactions.\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 6.25 sec. Users per second: 770\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 7.47 sec. Users per second: 644\n",
      "EvaluatorHoldout: Processed 4811 (100.0%) in 7.22 sec. Users per second: 666\n",
      "Recommender_Base_Class: URM Detected 19 ( 0.1%) items with no interactions.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for dimension 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m timestep \u001b[39min\u001b[39;00m timesteps:  \n\u001b[1;32m     21\u001b[0m     auto_diffusion_instance_test\u001b[39m.\u001b[39minference_timesteps \u001b[39m=\u001b[39m timestep\n\u001b[0;32m---> 22\u001b[0m     two_level_rec_test \u001b[39m=\u001b[39m TwoLevelRec(URM_train\u001b[39m=\u001b[39;49mURM_train\u001b[39m+\u001b[39;49mURM_validation,\n\u001b[1;32m     23\u001b[0m                                         recommender1\u001b[39m=\u001b[39;49mauto_diffusion_instance_test,\n\u001b[1;32m     24\u001b[0m                                         recommender2\u001b[39m=\u001b[39;49mitemKNN_instance_test,\n\u001b[1;32m     25\u001b[0m                                         max_cutoff\u001b[39m=\u001b[39;49m\u001b[39m350\u001b[39;49m)\n\u001b[1;32m     26\u001b[0m     \u001b[39mfor\u001b[39;00m traditional_rec_name, traditional_rec_instance \u001b[39min\u001b[39;00m recommenders_instances_test\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     27\u001b[0m         expected_name \u001b[39m=\u001b[39m auto_diffusion_instance\u001b[39m.\u001b[39mRECOMMENDER_NAME \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m traditional_rec_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_TwoLevelRec\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/TESI/Thesis_DiffusionRecommender-main/RecommenderLuca/TwoLevelRec.py:21\u001b[0m, in \u001b[0;36mTwoLevelRec.__init__\u001b[0;34m(self, URM_train, recommender1, recommender2, max_cutoff)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecommender2 \u001b[39m=\u001b[39m recommender2\n\u001b[1;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mRECOMMENDER_NAME \u001b[39m=\u001b[39m recommender1\u001b[39m.\u001b[39mRECOMMENDER_NAME \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m recommender2\u001b[39m.\u001b[39mRECOMMENDER_NAME \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTwoLevelRec\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecommendations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecommender1\u001b[39m.\u001b[39;49mrecommend(\u001b[39mlist\u001b[39;49m(\u001b[39mrange\u001b[39;49m(\u001b[39m0\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mURM_train\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])), max_cutoff)\n",
      "File \u001b[0;32m~/Desktop/TESI/Thesis_DiffusionRecommender-main/Recommenders/BaseRecommender.py:147\u001b[0m, in \u001b[0;36mBaseRecommender.recommend\u001b[0;34m(self, user_id_array, cutoff, remove_seen_flag, items_to_compute, remove_top_pop_flag, remove_custom_items_flag, return_scores)\u001b[0m\n\u001b[1;32m    143\u001b[0m cutoff \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(cutoff, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mURM_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39m# Compute the scores using the model-specific function\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39m# Vectorize over all users in user_id_array\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m scores_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_item_score(user_id_array, items_to_compute\u001b[39m=\u001b[39;49mitems_to_compute)\n\u001b[1;32m    150\u001b[0m \u001b[39mfor\u001b[39;00m user_index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(user_id_array)):\n\u001b[1;32m    152\u001b[0m     user_id \u001b[39m=\u001b[39m user_id_array[user_index]\n",
      "File \u001b[0;32m~/Desktop/TESI/Thesis_DiffusionRecommender-main/Diffusion/DiffusionRecommender.py:274\u001b[0m, in \u001b[0;36mDiffusionRecommender._compute_item_score\u001b[0;34m(self, user_id_array, items_to_compute)\u001b[0m\n\u001b[1;32m    265\u001b[0m user_profile_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mURM_train[user_id_array]\n\u001b[1;32m    266\u001b[0m user_profile_batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msparse_csr_tensor(user_profile_batch\u001b[39m.\u001b[39mindptr,\n\u001b[1;32m    267\u001b[0m                                             user_profile_batch\u001b[39m.\u001b[39mindices,\n\u001b[1;32m    268\u001b[0m                                             user_profile_batch\u001b[39m.\u001b[39mdata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m                                             device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice,\n\u001b[1;32m    272\u001b[0m                                             requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mto_dense()\n\u001b[0;32m--> 274\u001b[0m user_profile_inference \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49msample_from_user_profile(user_profile_batch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference_timesteps)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    276\u001b[0m \u001b[39mif\u001b[39;00m items_to_compute \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     item_scores \u001b[39m=\u001b[39m user_profile_inference\n",
      "File \u001b[0;32m~/Desktop/TESI/Thesis_DiffusionRecommender-main/Diffusion/DiffusionRecommender.py:138\u001b[0m, in \u001b[0;36m_GaussianDiffusionModel.sample_from_user_profile\u001b[0;34m(self, user_profile, inference_timesteps)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    136\u001b[0m     gaussian_noise \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn_like(user_profile, device\u001b[39m=\u001b[39muser_profile\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 138\u001b[0m     user_profile_inference \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_sample(x_start \u001b[39m=\u001b[39;49m user_profile, t \u001b[39m=\u001b[39;49m torch\u001b[39m.\u001b[39;49mtensor([inference_timesteps], device\u001b[39m=\u001b[39;49muser_profile\u001b[39m.\u001b[39;49mdevice, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong), gaussian_noise \u001b[39m=\u001b[39;49m gaussian_noise)\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m timestep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(inference_timesteps, \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    141\u001b[0m         user_profile_inference \u001b[39m=\u001b[39m user_profile_inference \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_encoding\u001b[39m.\u001b[39mget_encoding(torch\u001b[39m.\u001b[39mtensor([timestep], device\u001b[39m=\u001b[39muser_profile\u001b[39m.\u001b[39mdevice))\n",
      "File \u001b[0;32m~/Desktop/TESI/Thesis_DiffusionRecommender-main/Diffusion/DiffusionRecommender.py:93\u001b[0m, in \u001b[0;36m_GaussianDiffusionModel.q_sample\u001b[0;34m(self, x_start, t, gaussian_noise)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mq_sample\u001b[39m(\u001b[39mself\u001b[39m, x_start, t, gaussian_noise \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     79\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39m    Apply noise to the sample by calculating the total noise that would be applied after t steps.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39m    The sum of t gaussian noise steps is also a gaussian so we can avoid to iterate t steps and calculate\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m    :return:\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     a_signed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnoise_schedule\u001b[39m.\u001b[39;49mget_a_signed(t)\n\u001b[1;32m     94\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(t)\n\u001b[1;32m     95\u001b[0m     x_noisy \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(a_signed)\u001b[39m.\u001b[39mreshape(batch_size, \u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mx_start \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39msqrt(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m a_signed)\u001b[39m.\u001b[39mreshape(batch_size, \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m gaussian_noise\n",
      "File \u001b[0;32m~/Desktop/TESI/Thesis_DiffusionRecommender-main/Diffusion/NoiseSchedule.py:35\u001b[0m, in \u001b[0;36mLinearNoiseSchedule.get_a_signed\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_a_signed\u001b[39m(\u001b[39mself\u001b[39m, step):\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_alpha_values[step]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for dimension 0 with size 6"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "directory = \"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/experiment_data/CiteULike_a\"\n",
    "# Read the CSV\n",
    "df = pd.read_csv('/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/experiment_data/2023-07-31 03:41:53/cutoff_10/1/best_models_last_1_timesteps.csv')\n",
    "\n",
    "# Define recommenders\n",
    "recommenders_instances_test = {\n",
    "    \"ItemKNNCFRecommender\": itemKNN_instance_test,\n",
    "    \"SLIMElasticNetRecommender\": slim_elastic_instance_test,\n",
    "    \"IALSRecommender\": matrix_fact_instance_test\n",
    "}\n",
    "\n",
    "timesteps = [1, 2, 3, 4, 5, 10, 15, 20, 30, 40, 60, 80, 100, 150, 200, 250, 300, 350, 400, 500]\n",
    "#!!! best model di diffusion autoencoder ha NOISE timesteps =429 quindi non di possono dare INFERENCE timesteps>429 perchè quando viene preso beta o alpha[430+] c'è un errore siccome è stato generato beta solo fino a noise timesteps, quindi 429\n",
    "\n",
    "\n",
    "# Loop through each row in the dataframe\n",
    "  # Once you have the model ready, loop through timesteps and perform operations\n",
    "for timestep in timesteps:  \n",
    "    auto_diffusion_instance_test.inference_timesteps = timestep\n",
    "    two_level_rec_test = TwoLevelRec(URM_train=URM_train+URM_validation,\n",
    "                                        recommender1=auto_diffusion_instance_test,\n",
    "                                        recommender2=itemKNN_instance_test,\n",
    "                                        max_cutoff=350)\n",
    "    for traditional_rec_name, traditional_rec_instance in recommenders_instances_test.items():\n",
    "        expected_name = auto_diffusion_instance.RECOMMENDER_NAME + '_' + traditional_rec_name + '_TwoLevelRec'\n",
    "      \n",
    "        two_level_rec_test.set_rec2(traditional_rec_instance)\n",
    "                # Instantiate the TwoLevelRec model with correct parameters\n",
    "        # Fit the model\n",
    "        two_level_rec_test.fit(n_items_to_rank=40)\n",
    "        result_df, _ =evaluator_test.evaluateRecommender(two_level_rec_test)\n",
    "        result_df[\"RECOMMENDER\"] = two_level_rec_test.RECOMMENDER_NAME\n",
    "        result_df[\"PARAMS\"] = str(40)\n",
    "        result_df[\"TIMESTEPS\"] = timestep\n",
    "        filename = expected_name+ \".csv\"\n",
    "        filename = os.path.join(directory, filename)\n",
    "\n",
    "        if os.path.isfile(filename):\n",
    "                # If it exists, append without writing the header\n",
    "                pd.DataFrame(result_df.loc[10]).transpose().to_csv(filename, mode='a', header=False, index=False)\n",
    "        else:\n",
    "                # If it doesn't exist, create it, write the header\n",
    "                pd.DataFrame(result_df.loc[10]).transpose().to_csv(filename, mode='w', header=True, index=False)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "directory = \"/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/experiment_data/CiteULike_a\"\n",
    "# Read the CSV\n",
    "df = pd.read_csv('/Users/lucaortolomo/Desktop/TESI/Thesis_DiffusionRecommender-main/experiment_data/2023-07-31 09:13:50/cutoff_10/1/best_models_last_1_timesteps.csv')\n",
    "\n",
    "# Define recommenders\n",
    "recommenders_instances_test = {\n",
    "    #\"ItemKNNCFRecommender\": itemKNN_instance_test,\n",
    "    \"SLIMElasticNetRecommender\": slim_elastic_instance_test,\n",
    "    #\"IALSRecommender\": matrix_fact_instance_test\n",
    "}\n",
    "\n",
    "timesteps = [1, 2, 3, 4, 5, 10, 15, 20, 30, 40, 60, 80, 100, 150, 200, 250, 300, 350, 400, 500]\n",
    "#!!! best model di diffusion autoencoder ha NOISE timesteps =429 quindi non di possono dare INFERENCE timesteps>429 perchè quando viene preso beta o alpha[430+] c'è un errore siccome è stato generato beta solo fino a noise timesteps, quindi 429\n",
    "\n",
    "# Loop through each row in the dataframe\n",
    "  # Once you have the model ready, loop through timesteps and perform operations\n",
    "for timestep in timesteps:  # Assuming you have a list of timesteps defined somewhere\n",
    "    auto_diffusion_instance_test.inference_timesteps = timestep\n",
    "    \n",
    "                                        \n",
    "    for traditional_rec_name, traditional_rec_instance in recommenders_instances_test.items():\n",
    "        expected_name = traditional_rec_name + '_' + auto_diffusion_instance.RECOMMENDER_NAME + '_TwoLevelRec'\n",
    "       \n",
    "        # Fit the model\n",
    "        two_level_rec_test = TwoLevelRec(URM_train=URM_train+URM_validation,\n",
    "                                        recommender1=itemKNN_instance_test ,\n",
    "                                        recommender2=auto_diffusion_instance_test,\n",
    "                                        max_cutoff=350)\n",
    "        two_level_rec_test.set_rec2(traditional_rec_instance)\n",
    "\n",
    "        two_level_rec_test.fit(n_items_to_rank=40)\n",
    "        result_df, _ =evaluator_test.evaluateRecommender(two_level_rec_test)\n",
    "        result_df[\"RECOMMENDER\"] = two_level_rec_test.RECOMMENDER_NAME\n",
    "        result_df[\"PARAMS\"] = str(40)\n",
    "        result_df[\"TIMESTEPS\"] = timestep\n",
    "        filename = expected_name+ \".csv\"\n",
    "        filename = os.path.join(directory, filename)\n",
    "\n",
    "        if os.path.isfile(filename):\n",
    "                # If it exists, append without writing the header\n",
    "                pd.DataFrame(result_df.loc[10]).transpose().to_csv(filename, mode='a', header=False, index=False)\n",
    "        else:\n",
    "                # If it doesn't exist, create it, write the header\n",
    "                pd.DataFrame(result_df.loc[10]).transpose().to_csv(filename, mode='w', header=True, index=False)\n",
    "\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
